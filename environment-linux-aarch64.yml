name: invokeai
channels:
  - pytorch
  - conda-forge
dependencies:
  - python=3.9.*
  - pip>=22.2.2
  - cudatoolkit
  - pytorch
  - torchvision
  - numpy=1.19
  - imageio=2.9.0
  - opencv=4.6.0
  - pillow=8.*
  - flask=2.1.*
  - flask_cors=3.0.10
  - flask-socketio=5.3.0
  - send2trash=1.8.0
  - eventlet
  - albumentations=0.4.3
  - pudb=2019.2
  - imageio-ffmpeg=0.4.2
  - pytorch-lightning=1.7.7
  - streamlit
  - einops=0.3.0
  - kornia=0.6
  - torchmetrics=0.7.0
  - transformers=4.21.3
  - torch-fidelity=0.3.0
  - tokenizers>=0.11.1,!=0.11.3,<0.13
  - pip:
      - getpass_asterisk
      - omegaconf==2.1.1
      - realesrgan==0.2.5.0
      - test-tube>=0.7.5
      - pyreadline3
      - dependency_injector==4.40.0
      - -e git+https://github.com/openai/CLIP.git@main#egg=clip
      - -e git+https://github.com/CompVis/taming-transformers.git@master#egg=taming-transformers
      - -e git+https://github.com/Birch-san/k-diffusion.git@mps#egg=k_diffusion
      - -e git+https://github.com/TencentARC/GFPGAN.git#egg=gfpgan
      - -e git+https://github.com/invoke-ai/clipseg.git@models-rename#egg=clipseg
      - -e .
variables:
  PYTORCH_ENABLE_MPS_FALLBACK: 1
